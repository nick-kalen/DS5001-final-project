{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8351558-80af-4eba-85a0-83f01c747ee7",
   "metadata": {},
   "source": [
    "# Data Model\n",
    "\n",
    "DS 5001 Spring 2023 Final Project\n",
    "\n",
    "Rachel Grace Treene\n",
    "\n",
    "rg5xm@virginia.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7490e839-7545-4421-b108-57c16ceb2841",
   "metadata": {},
   "source": [
    "## Output: directory of files produced to meet requirements of the project\n",
    "- **CORPUS**: annotated tokens table (https://github.com/rachelgracetreene/text-analytics-final-project/blob/main/output/CORPUS.csv)\n",
    "    - pos_tuple: a tuple representing the part of speech and the token string\n",
    "    - pos: abbreviation representing the part of speech\n",
    "    - token_str: string representing the token with its formatting (capital letters, etc.)\n",
    "    - term_str: string representing the term without formatting like capital letters\n",
    "- **LDA-PHI**: topics and term counts (https://github.com/rachelgracetreene/text-analytics-final-project/blob/main/output/LDA-PHI.csv)\n",
    "    - T00, T01, T02, ... T18, T19: features representing topics 1-20 produced in LDA\n",
    "- **LDA-THETA**: document and topic concentrations (https://github.com/rachelgracetreene/text-analytics-final-project/blob/main/output/LDA-THETA.csv)\n",
    "    - T00, T01, T02, ... T18, T19: features representing topics 1-20 produced in LDA\n",
    "- **LIB**: metadata for the source files (https://github.com/rachelgracetreene/text-analytics-final-project/blob/main/output/LIB.csv)\n",
    "    - title: title of each document\n",
    "    - chapter_regex: regex corresponding with the chapter titles\n",
    "    - book_len: number of tokens\n",
    "    - n_chaps: number of chapters\n",
    "    - kendall_sum: kendall statistic for rank correlation measurement\n",
    "- **PCA-DCM**: table of documents and components (https://github.com/rachelgracetreene/text-analytics-final-project/blob/main/output/PCA-DCM.csv)\n",
    "    - PC0, PC1, ... PC8, PC9: features representing principal components 1-10 produced in PCA\n",
    "    - title: title of each document\n",
    "    - chapter_regex: regex corresponding with the chapter titles\n",
    "    - book_len: number of tokens\n",
    "    - n_chaps: number of chapters\n",
    "    - kendall_sum: kendall statistic for rank correlation measurement\n",
    "    - doc: title of each document with corresponding chapter numbers of each observation\n",
    "- **PCA-LOADINGS**: table of components and word counts (https://github.com/rachelgracetreene/text-analytics-final-project/blob/main/output/PCA-LOADINGS.csv)\n",
    "    - PC0, PC1, ... PC8, PC9: features representing principal components 1-10 produced in PCA\n",
    "- **SA-DOCEMOTIONS**: sentiment polarity and emotions for each document (https://github.com/rachelgracetreene/text-analytics-final-project/blob/main/output/SA-DOCEMOTIONS.csv)\n",
    "    - anger: measurement of anger sentiment in each book\n",
    "    - anticipation: measurement of anticipation sentiment in each book\n",
    "    - disgust: measurement of disgust sentiment in each book\n",
    "    - fear: measurement of fear sentiment in each book\n",
    "    - joy: measurement of joy sentiment in each book\n",
    "    - sadness: measurement of sadness sentiment in each book\n",
    "    - surprise: measurement of surprise sentiment in each book\n",
    "    - trust: measurement of trust sentiment in each book\n",
    "    - polarity: measurement of overall sentiment in each book\n",
    "- **SA-VOCAB**: sentiment and emotion values as feature (https://github.com/rachelgracetreene/text-analytics-final-project/blob/main/output/SA-VOCAB.csv)\n",
    "    - n: count of term in corpus\n",
    "    - p: probabiliy of term occurrence in corpus\n",
    "    - i: information for each term in corpus\n",
    "    - n_chars: number of characters for each term in corpus\n",
    "    - max_pos: maximally-occuring part of speech for term\n",
    "    - n_pos: number of unique parts of speech for the term\n",
    "    - cat_pos: tag for each unique part of speech for the term\n",
    "    - stop: dummy variable indicating whether a term is a stopword\n",
    "    - stem_porter: stem for the term according to the porter method\n",
    "    - stem_snowball: stem for the term according to the snowball method\n",
    "    - stem_lancaster: stem for the term according to the lancaster method\n",
    "    - dfidf: global boolean term entropy\n",
    "    - mean_tfidf: average significance of the term in a document\n",
    "    - anger, anticipation, disgust, fear, joy, sadness, surprise, trust, sentiment, negative, positive: features representing the sentiment analysis lexicon mapped to corpus terms\n",
    "    - polarity: measurement of overall sentiment for each term\n",
    "- **VOCAB**: extracted vocabulary from corpus (https://github.com/rachelgracetreene/text-analytics-final-project/blob/main/output/VOCAB.csv)\n",
    "    - n: count of term in corpus\n",
    "    - p: probabiliy of term occurrence in corpus\n",
    "    - i: information for each term in corpus\n",
    "    - n_chars: number of characters for each term in corpus\n",
    "    - max_pos: maximally-occuring part of speech for term\n",
    "    - n_pos: number of unique parts of speech for the term\n",
    "    - cat_pos: tag for each unique part of speech for the term\n",
    "    - stop: dummy variable indicating whether a term is a stopword\n",
    "    - stem_porter: stem for the term according to the porter method\n",
    "    - stem_snowball: stem for the term according to the snowball method\n",
    "    - stem_lancaster: stem for the term according to the lancaster method\n",
    "    - dfidf: global boolean term entropy\n",
    "    - mean_tfidf: average significance of the term in a document\n",
    "- **W2V-VOCAB**: word2vec terms and embeddings (https://github.com/rachelgracetreene/text-analytics-final-project/blob/main/output/W2V-VOCAB.csv)\n",
    "    - n: count of term in corpus\n",
    "    - p: probabiliy of term occurrence in corpus\n",
    "    - i: information for each term in corpus\n",
    "    - n_chars: number of characters for each term in corpus\n",
    "    - max_pos: maximally-occuring part of speech for term\n",
    "    - n_pos: count of unique parts of speech for the term\n",
    "    - cat_pos: tag for each unique part of speech for the term\n",
    "    - stop: dummy variable indicating whether a term is a stopword\n",
    "    - stem_porter: stem for the term according to the porter method\n",
    "    - stem_snowball: stem for the term according to the snowball method\n",
    "    - stem_lancaster: stem for the term according to the lancaster method\n",
    "    - dfidf: global boolean term entropy\n",
    "    - mean_tfidf: average significance of the term in a document\n",
    "    - vector: representation of vectorized term in (x-coord, y-coord) form\n",
    "    - x: x-coordinate for vectorized term\n",
    "    - y: y-coordinate for vectorized term\n",
    "## Output-Viz: directory of files produced to be imported in the visualization notebook\n",
    "- **DOCS**: (https://github.com/rachelgracetreene/text-analytics-final-project/blob/main/output-viz/DOCS.csv)\n",
    "    - n: number of tokens in the chapter\n",
    "    - book_chap_sig: significance of the chapter\n",
    "- **MT**: top 1000 terms by DFIDF (https://github.com/rachelgracetreene/text-analytics-final-project/blob/main/output-viz/MT.csv)\n",
    "    - pressed, recognized, perfectly...: aggregate tfidf (significance of term in book) for top 1000 terms of corpus by DFIDF excluding proper nouns\n",
    "- **PAIRS**: correlations between books with various measures (https://github.com/rachelgracetreene/text-analytics-final-project/blob/main/output-viz/PAIRS.csv)\n",
    "    - correl: correlation between documents a and b\n",
    "    - euclidean: euclidean distance between documents a and b\n",
    "    - cosine: cosine distance between documents a and b\n",
    "    - cityblock: cityblock distance between documents a and b\n",
    "    - jaccard: jaccard distance between documents a and b\n",
    "    - js: js distance between documents a and b\n",
    "- **POS-GROUP**: part of speech group characteristics (https://github.com/rachelgracetreene/text-analytics-final-project/blob/main/output-viz/POS-GROUP.csv)\n",
    "    - n: count of words of each part of speech in corpus\n",
    "    - pos_def: definition of each part of speech\n",
    "    - p: probability of each part of speech\n",
    "    - i: information for each part of speech\n",
    "    - h: entropy of each part of speech\n",
    "    - n_terms: clount of unique terms of each part of speech\n",
    "    - n_tokens: count of tokens of each part of speech\n",
    "- **POS**: parts of speech (https://github.com/rachelgracetreene/text-analytics-final-project/blob/main/output-viz/POS.csv)\n",
    "    - pos_def: definition of each part of speech\n",
    "    - n: count of each part of speech in corpus\n",
    "    - pos_group: part of speech group associated with each part of speech\n",
    "    - punc: boolean with True for all parts of speech that are punctuation\n",
    "- **SA-CHAPEMOTIONS**: sentiment polarity and emotions for each chapter (https://github.com/rachelgracetreene/text-analytics-final-project/blob/main/output-viz/SA-CHAPEMOTIONS.csv)\n",
    "    - anger: measurement of anger sentiment in each chapter\n",
    "    - anticipation: measurement of anticipation sentiment in each chapter\n",
    "    - disgust: measurement of disgust sentiment in each chapter\n",
    "    - fear: measurement of fear sentiment in each chapter\n",
    "    - joy: measurement of joy sentiment in each chapter\n",
    "    - sadness: measurement of sadness sentiment in each chapter\n",
    "    - surprise: measurement of surprise sentiment in each chapter\n",
    "    - trust: measurement of trust sentiment in each chapter\n",
    "    - polarity: measurement of overall sentiment in each chapter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
